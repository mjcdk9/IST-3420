knitr::opts_chunk$set(echo = TRUE) # echo: whether to include R source code in the output file
knitr::opts_chunk$set(echo = TRUE) # echo: whether to include R source code in the output file
knitr::opts_chunk$set(echo = TRUE) # echo: whether to include R source code in the output file
# Clean the environment
rm(list = ls())
# Read data file
call_data <- read.csv(file = "CallsData.csv", header = TRUE)
# Show the head of the dataset
head(call_data)
# Show the structure of the dataset
str(call_data)
# Summary statistics
summary(call_data)
int?
?int
?num
?num()
# Select Area Code and Phone number and combine them into a matrix
phone <- cbind(as.character(call_data$Phone), call_data$Area.Code)
colnames(phone) <- c("AreaCode","PhoneNum")
head(phone)
colnames(phone) <- c("PhoneNum", "AreaCode")
head(phone)
# Select Area Code and Phone number and combine them into a matrix
phone <- cbind(call_data$Area.Code, as.character(call_data$Phone))
colnames(phone) <- c("AreaCode","PhoneNum")
head(phone)
head(phone)
str(phone)
summary(phone)
knitr::opts_chunk$set(echo = TRUE)
# Clean the environment
rm(list = ls())
# Load RSQLite package
library("RSQLite")
# Specify the database file
dbfile <- "TelecomService.sqlite"
# Create a database connection
con <- dbConnect(dbDriver("SQLite"), dbname = dbfile)
# Show existing tables
dbListTables(con)
# Get call data
call_data <- dbGetQuery(con, "SELECT * FROM Call")
head(call_data)
summary(call_data)
str(call_data)
# Get call data
call_data <- dbGetQuery(con, "SELECT * FROM Call")
head(call_data)
summary(call_data)
str(call_data)
# Get contract data
contract_data <- dbGetQuery(con, "SELECT * FROM Contract")
head(contract_data)
summary(contract_data)
str(contract_data)
# Get both call and contract data
all_data <- dbGetQuery(con,
"SELECT * FROM Call a, Contract b WHERE a.AreaCode = b.AreaCode AND a.Phone = b.Phone")
head(all_data)
summary(all_data)
str(all_data)
# Get both call and contract data
all_data <- dbGetQuery(con,
"SELECT * FROM Call a, Contract b WHERE a.AreaCode = b.AreaCode AND a.Phone = b.Phone")
head(all_data)
summary(all_data)
str(all_data)
all_data <- subset(all_data, select = -c(22, 23))
head(all_data)
str(all_data)
knitr::opts_chunk$set(echo = TRUE)
# Clean the environment
rm(list = ls())
# Load RSQLite package
library("RSQLite")
# Specify the database file
dbfile <- "TelecomService.sqlite"
# Create a database connection
con <- dbConnect(dbDriver("SQLite"), dbname = dbfile)
knitr::opts_chunk$set(echo = TRUE)
# Clean the environment
rm(list = ls())
# Load packages
library("XML")
library("httr")
# Or you can use require() to load needed packages
# Specify URL
url <- "https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population"
print(url)
knitr::opts_chunk$set(echo = TRUE)
url <- getURL("https://finance.yahoo.com/quote/FB/history?p=FB")
url <- GET("https://finance.yahoo.com/quote/FB/history?p=FB")
facebook_df <- as.data.frame(readHTMLTable(url))
# Load packages
library("XML")
library("httr")
# Or you can use require() to load needed packages
# Specify URL
url <- "https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population"
print(url)
# Download the content of the URL
url_content <- GET(url)
print(substr(url_content,1,800))
knitr::opts_chunk$set(echo = TRUE)
url <- getURL("https://finance.yahoo.com/quote/FB/history?p=FB")
# Parse the HTML/XML content to generate an R structure representing the HTML/XML tree
doc <- htmlParse(url_content)
tables <- readHTMLTable(doc)
str(tables)
str(tables)
url <- GET("https://finance.yahoo.com/quote/FB/history?p=FB")
facebook_df <- as.data.frame(readHTMLTable(url))
facebook_df <- as.data.frame(url)
facebook_df <- as.data.frame(readHTMLTable(htmlParse(url)))
facebook_df
View(facebook_df)
attributes(facebook_df)
str(facebook_df)
colnames(facebook_df)
facebook_df <- facebook_df %>%
rename(Date = NULL.Date,
Open = NULL.Open,
High = NULL.High,
Low = NULL.Low,
Close = NULL.Close.,
"Adj Close" = NULL.Adj.Close..,
Volume = NULL.Volume)
library(dplyr)
facebook_df <- facebook_df %>%
rename(Date = NULL.Date,
Open = NULL.Open,
High = NULL.High,
Low = NULL.Low,
Close = NULL.Close.,
"Adj Close" = NULL.Adj.Close..,
Volume = NULL.Volume)
colnames(facebook_df)
summary(facebook_df)
knitr::opts_chunk$set(echo = TRUE)
# Clean the environment
rm(list = ls())
# Load packages
library("XML")
library("httr")
# Or you can use require() to load needed packages
# Specify URL
url <- "https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population"
print(url)
# Download the content of the URL
url_content <- GET(url)
print(substr(url_content,1,800))
# Parse the HTML/XML content to generate an R structure representing the HTML/XML tree
doc <- htmlParse(url_content)
tables <- readHTMLTable(doc)
str(tables)
# Convert the 1st element of the list to data frame
pop_df <- data.frame(tables[1])
attributes(pop_df)
str(pop_df)
head(pop_df)
colnames(pop_df) <- c("Rank","Country/Territory","Population","Date","% of World Population","Source")
is.factor(pop_df$Population)
# Convert factors into numbers for Population column
pop_df$Population <- as.numeric(gsub(",","",pop_df$Population))  # Use gsub() to remove all commas in Population
str(pop_df)
str(pop_df)
str(pop_df)
pop_df_new <- pop_df[-c(1),]
head(pop_df_new)
row.names(pop_df_new) <- 1:nrow(pop_df_new)
head(pop_df_new)
top10 <- head(pop_df_new, n = 10L)
plot(top10$Population, type = "l")
knitr::opts_chunk$set(echo = TRUE)
library(XML)
library(httr)
library(dplyr)
url <- GET("https://finance.yahoo.com/quote/FB/history?p=FB")
facebook_df <- as.data.frame(readHTMLTable(htmlParse(url)))
attributes(facebook_df)
str(facebook_df)
colnames(facebook_df)
facebook_df <- facebook_df %>%
rename(Date = NULL.Date,
Open = NULL.Open,
High = NULL.High,
Low = NULL.Low,
Close = NULL.Close.,
"Adj Close" = NULL.Adj.Close..,
Volume = NULL.Volume)
colnames(facebook_df)
summary(facebook_df)
write.csv(facebook_df, file = "facebook_prices.csv", row.names = F)
knitr::opts_chunk$set(echo = TRUE)
# Clean the environment
rm(list = ls())
# Load packages
library("XML")
library("RCurl")
# Load XML package
library("XML")
# Parse XML file to generate an R structure
doc <- xmlParse(file = "Books.xml")
# Show the content of doc
print(doc)
# Get the root node
top <- xmlRoot(doc)
# Show the content of top
print(top)
# Show tage name of the root node
xmlName(top)
# Show child nodes of the root node
names(top)
# Show child nodes of the 1st book
names(top[[1]])
# Show title of the 1st book
top[[1]][["title"]]
# Show year of the 1st book
top[[1]][["year"]]
# Show price of the 1st book
top[[1]][["price"]]
b_title <- xpathSApply(doc,"//bookstore/book/title", xmlValue)
print(b_title)
b_category <- xpathSApply(doc,"//bookstore/book/@category")
b_author <- xpathSApply(doc,"//bookstore/book/author", xmlValue)
b_year <- xpathSApply(doc,"//bookstore/book/year", xmlValue)
b_price <- xpathSApply(doc,"//bookstore/book/price", xmlValue)
# Generate a book data frame
book_df <- data.frame(b_title,b_category,b_author,b_year,b_price)
colnames(book_df) <- c("Title","Category","Author","Year","Price")
print(book_df)
View(book_df)
knitr::opts_chunk$set(echo = TRUE)
b_category <- xpathSApply(doc,"//bookstore/book/@category")
b_title <- xpathSApply(doc,"//bookstore/book/title", xmlValue)
# Load jsonlite package
library(jsonlite)
# data.frames must be converted into a list before converting into JSON
j_book <- toJSON(as.list(book_df))
knitr::opts_chunk$set(echo = TRUE)
# Clean the environment
rm(list = ls())
# Load packages
library("XML")
library("RCurl")
# Load XML package
library("XML")
# Parse XML file to generate an R structure
doc <- xmlParse(file = "Books.xml")
# Show the content of doc
print(doc)
# Get the root node
top <- xmlRoot(doc)
# Show the content of top
print(top)
# Show tage name of the root node
xmlName(top)
# Show child nodes of the root node
names(top)
# Show child nodes of the 1st book
names(top[[1]])
# Show title of the 1st book
top[[1]][["title"]]
# Show year of the 1st book
top[[1]][["year"]]
# Show price of the 1st book
top[[1]][["price"]]
b_title <- xpathSApply(doc,"//bookstore/book/title", xmlValue)
print(b_title)
b_category <- xpathSApply(doc,"//bookstore/book/@category")
b_author <- xpathSApply(doc,"//bookstore/book/author", xmlValue)
b_year <- xpathSApply(doc,"//bookstore/book/year", xmlValue)
b_price <- xpathSApply(doc,"//bookstore/book/price", xmlValue)
# Generate a book data frame
book_df <- data.frame(b_title,b_category,b_author,b_year,b_price)
colnames(book_df) <- c("Title","Category","Author","Year","Price")
print(book_df)
# data.frames must be converted into a list before converting into JSON
j_book <- toJSON(as.list(book_df))
print(j_book)
# data.frames must be converted into a list before converting into JSON
j_book <- toJSON(as.list(book_df))
print(j_book)
# Convert JSON to data frame
book_df2 <- data.frame(fromJSON(j_book))
print(book_df2)
library(readr)
library(readr)
write_lines(j_book,"books.json")
knitr::opts_chunk$set(echo = TRUE)
appid <- 271590 # Choose Grand Theft Auto V whose App ID is 271590
n_new <- 100 # Number of news to get
# Generate url for the app
url <- paste("http://api.steampowered.com/ISteamNews/GetNewsForApp/v0002/?appid=",
appid,
"&count=", n_new, "&maxlength=300&format=json",
sep = "")
# Check the url again
url
# Download HTTP response
content = RCurl::getURI(url)
# Print the first 800 characters
print(substr(content,1,800))
# Create a list
library("rjson")
