print("Has the largest number of visits")
weekday.freq %>% which.max()
cross_tabulate <- table(weblog$weekday, weblog$request.uri)
cross_tabulate
weblog.barplot <- table(weblog$weekday)
barplot(weblog.barplot)
weblog.stacked <- table(weblog$request.uri, weblog$request.method)
barplot(weblog.stacked,
main = "Distributuion of Visits",
col = rainbow(2),
legend = rownames(weblog.stacked))
weblog.stacked <- table(weblog$request.uri, weblog$request.method)
barplot(weblog.stacked,
main = "Distributuion of Visits",
col = rainbow(2),
legend = rownames(weblog.stacked))
weblog.stacked <- table(weblog$request.method, weblog$request.uri)
barplot(weblog.stacked,
main = "Distributuion of Visits",
col = rainbow(2),
legend = rownames(weblog.stacked))
barplot(weblog.stacked,
main = "Distributuion of Visits",
col = rainbow(3),
legend = rownames(weblog.stacked))
# Five-Number Summary
z1 <- c(23,12,24,55,60,34,20,17,19,37,43,51)
z1[order(z1)] # Sort data
quantile(z1,type = 7)  # Default type
quantile(z1,type = 2)  # Simple manual caculation method
?quantile
# Box plot of a variable
set.seed(1)
x1 <- rnorm(100, mean = 5, sd = 2)
x1[88] <- 12; x1[89] <- 11.8  # Set two outliers
quantile(x1)
# Box plot of a variable
set.seed(1)
x1 <- rnorm(100, mean = 5, sd = 2)
x1
mean(x1)
# Box plot of a variable
set.seed(1)
x1 <- rnorm(100, mean = 5.0, sd = 2)
mean(x1)
# Box plot of a variable
set.seed(1)
x1 <- rnorm(100, mean = 6, sd = 2)
mean(x1)
# Box plot of a variable
set.seed(1)
x1 <- rnorm(100, mean = 5, sd = 2)
x1[88] <- 12; x1[89] <- 11.8  # Set two outliers
quantile(x1)
mean(x1)
summary(x1)
boxplot(x1)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(dplyr)
library(jsonlite)
weblog <- stream_in(file("weblog_clean.jsonlines"))
str(weblog)
weblog$request.datetime <- as.POSIXct(weblog$request.datetime, format = "%Y-%m-%d %H:%M:%S")
summary(weblog)
weekday.freq <- table(weblog$weekday)
sort(weekday.freq)
print("Has the largest number of visits")
weekday.freq %>% which.max()
cross_tabulate <- table(weblog$weekday, weblog$request.uri)
cross_tabulate
print("There are 4407 visits on the faq.html page on Friday")
weblog.barplot <- table(weblog$weekday)
barplot(weblog.barplot, col = rainbow(20), cex.names = .8)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(dplyr)
library(jsonlite)
weblog <- stream_in(file("weblog_clean.jsonlines"))
str(weblog)
weblog$request.datetime <- as.POSIXct(weblog$request.datetime, format = "%Y-%m-%d %H:%M:%S")
summary(weblog)
weekday.freq <- table(weblog$weekday)
sort(weekday.freq)
print("Has the largest number of visits")
weekday.freq %>% which.max()
cross_tabulate <- table(weblog$weekday, weblog$request.uri)
cross_tabulate
print("There are 4407 visits on the faq.html page on Friday")
weblog.barplot <- table(weblog$weekday)
barplot(weblog.barplot, col = rainbow(20), cex.names = .8)
weblog.stacked <- table(weblog$request.method, weblog$request.uri)
barplot(weblog.stacked,
main = "Distributuion of Visits",
col = rainbow(3),
legend = rownames(weblog.stacked))
weblog.piechart <- table(weblog$request.uri)
labels <- paste(names(weblog.piechart),"\n", weblog.piechart, sep = "")
pie(weblog.piechart, labels = labels, col = rainbow(5))
piechart <- round(weblog.piechart/sum(weblog.piechart)*100, digits = 1)
label2 <- paste(names(weblog.piechart), " visits\n", paste(piechart,"%"), sep="")
pie(piechart,
labels = label2,
col=rainbow(length(label2)))
quantile(weblog$response.size)
weblog.barplot <- table(weblog$weekday)
barplot(weblog.barplot, col = rainbow(2), cex.names = .8)
weblog.barplot <- table(weblog$weekday)
barplot(weblog.barplot, col = rainbow(2000), cex.names = .8)
weblog.barplot <- table(weblog$weekday)
barplot(weblog.barplot, col = rainbow(100000), cex.names = .8)
weblog.barplot <- table(weblog$weekday)
barplot(weblog.barplot, col = rainbow(1000000), cex.names = .8)
weblog.barplot <- table(weblog$weekday)
barplot(weblog.barplot, col = rainbow(10000000), cex.names = .8)
weblog.barplot <- table(weblog$weekday)
barplot(weblog.barplot, col = rainbow(100000000), cex.names = .8)
weblog.barplot <- table(weblog$weekday)
barplot(weblog.barplot, col = rainbow(20), cex.names = .8)
str(weblog)
cross_tabulate <- table( weblog$request.uri, weblog$weekday)
cross_tabulate
print("There are 4407 visits on the faq.html page on Friday")
cross_tabulate <- table( weblog$request.uri, weblog$weekday)
cross_tabulate
print("There are 4407 visits on the faq.html page on Friday")
cross_tabulate <- table(weblog$weekday, weblog$request.uri)
cross_tabulate
print("There are 4407 visits on the faq.html page on Friday")
weblog$weekday <- sort.default(weblog$weekday)
cross_tabulate <- table(weblog$weekday, weblog$request.uri)
cross_tabulate
cross_tabulate <- table(weblog$weekday, weblog$request.uri)
cross_tabulate
print("There are 4407 visits on the faq.html page on Friday")
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(dplyr)
library(jsonlite)
weblog <- stream_in(file("weblog_clean.jsonlines"))
str(weblog)
weblog$request.datetime <- as.POSIXct(weblog$request.datetime, format = "%Y-%m-%d %H:%M:%S")
summary(weblog)
weekday.freq <- table(weblog$weekday)
sort(weekday.freq)
print("Has the largest number of visits")
weekday.freq %>% which.max()
cross_tabulate <- table(weblog$weekday, weblog$request.uri)
cross_tabulate
print("There are 4407 visits on the faq.html page on Friday")
weblog.barplot <- table(weblog$weekday)
barplot(weblog.barplot, col = rainbow(20), cex.names = .8)
weblog.stacked <- table(weblog$request.method, weblog$request.uri)
barplot(weblog.stacked,
main = "Distributuion of Visits",
col = rainbow(3),
legend = rownames(weblog.stacked))
weblog.piechart <- table(weblog$request.uri)
labels <- paste(names(weblog.piechart),"\n", weblog.piechart, sep = "")
pie(weblog.piechart, labels = labels, col = rainbow(5))
piechart <- round(weblog.piechart/sum(weblog.piechart)*100, digits = 1)
label2 <- paste(names(weblog.piechart), " visits\n", paste(piechart,"%"), sep="")
pie(piechart,
labels = label2,
col=rainbow(length(label2)))
quantile(weblog$response.size)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(dplyr)
library(jsonlite)
weblog <- stream_in(file("weblog_clean.jsonlines"))
str(weblog)
weblog$request.datetime <- as.POSIXct(weblog$request.datetime, format = "%Y-%m-%d %H:%M:%S")
summary(weblog)
weekday.freq <- table(weblog$weekday)
sort(weekday.freq)
print("Has the largest number of visits")
weekday.freq %>% which.max()
cross_tabulate <- table(weblog$weekday, weblog$request.uri)
cross_tabulate
print("There are 4407 visits on the faq.html page on Friday")
weblog.barplot <- table(weblog$weekday)
barplot(weblog.barplot, col = rainbow(20), cex.names = .8)
weblog.stacked <- table(weblog$request.method, weblog$request.uri)
barplot(weblog.stacked,
main = "Distributuion of Visits",
col = rainbow(3),
legend = rownames(weblog.stacked))
weblog.piechart <- table(weblog$request.uri)
labels <- paste(names(weblog.piechart),"\n", weblog.piechart, sep = "")
pie(weblog.piechart, labels = labels, col = rainbow(5))
piechart <- round(weblog.piechart/sum(weblog.piechart)*100, digits = 1)
label2 <- paste(names(weblog.piechart), " visits\n", paste(piechart,"%"), sep="")
pie(piechart,
labels = label2,
col=rainbow(length(label2)))
quantile(weblog$response.size)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(dplyr)
library(jsonlite)
weblog <- stream_in(file("weblog_clean.jsonlines"))
str(weblog)
weblog$request.datetime <- as.POSIXct(weblog$request.datetime, format = "%Y-%m-%d %H:%M:%S")
summary(weblog)
weekday.freq <- table(weblog$weekday)
sort(weekday.freq)
print("Has the largest number of visits")
weekday.freq %>% which.max()
cross_tabulate <- table(weblog$weekday, weblog$request.uri)
cross_tabulate
print("There are 4407 visits on the faq.html page on Friday")
?col
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(dplyr)
library(tidyr)
library(ggplot2)
df <- read.csv("mst_enrollment2015.csv")
unique_countries <- unique(df$Country)
length(unique_countries)
# There are 89 unique countries
df <- df[-1]
df <- df %>% filter(Country == "United States")
df <- df %>% gather(Year, Enroll ,c(X2011,X2012,X2013,X2014,X2015))
df
df <- df %>% group_by(State) %>% summarise(Total_Enroll = sum(Enroll))
df
df <- df %>% filter(State != "Missouri")
df <- arrange(df,-Total_Enroll)
head(df)
us_states <- map_data("state")
str(us_states)
map_state <- unique(us_states$region)
df$Region <- tolower(df$State)
setdiff(df$Region,map_state)
gg <- ggplot()
gg <- gg + geom_map(data = us_states, map = us_states,
aes(x = long, y = lat, map_id = region),
fill="#ffffff", color="#ffffff", size=0.15)
gg
gg <- gg + geom_map(data=df, map = us_states,
aes(fill=Total_Enroll, map_id=Region),
color="#ffffff", size=0.15)
gg
gg <- ggplot()
gg <- gg + geom_map(data = us_states, map = us_states,
aes(x = long, y = lat, map_id = region),
fill="#ffffff", color="#ffffff", size=0.15)
gg
gg <- gg + geom_map(data=df, map = us_states,
aes(fill=Total_Enroll, map_id=Region),
color="#gggggg", size=0.15)
gg
gg <- ggplot()
gg <- gg + geom_map(data = us_states, map = us_states,
aes(x = long, y = lat, map_id = region),
fill="#ffffff", color="#ffffff", size=0.15)
gg
gg <- gg + geom_map(data=df, map = us_states,
aes(fill=Total_Enroll, map_id=Region),
color="#fffff", size=0.15)
gg
gg
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(dplyr)
library(tidyr)
library(ggplot2)
df <- read.csv("mst_enrollment2015.csv")
unique_countries <- unique(df$Country)
length(unique_countries)
# There are 89 unique countries
df <- df[-1]
df <- df %>% filter(Country == "United States")
df <- df %>% gather(Year, Enroll ,c(X2011,X2012,X2013,X2014,X2015))
df
df <- df %>% group_by(State) %>% summarise(Total_Enroll = sum(Enroll))
df
df <- df %>% filter(State != "Missouri")
df <- arrange(df,-Total_Enroll)
head(df)
us_states <- map_data("state")
str(us_states)
map_state <- unique(us_states$region)
df$Region <- tolower(df$State)
setdiff(df$Region,map_state)
gg <- ggplot()
gg <- gg + geom_map(data = us_states, map = us_states,
aes(x = long, y = lat, map_id = region),
fill="#ffffff", color="#ffffff", size=0.15)
gg
gg <- gg + geom_map(data=df, map = us_states,
aes(fill=Total_Enroll, map_id=Region),
color="#fffff", size=0.15)
gg
gg <- gg + geom_map(data=df, map = us_states,
aes(fill=Total_Enroll, map_id=Region),
color="#ffffff", size=0.15)
gg <- ggplot()
gg <- gg + geom_map(data = us_states, map = us_states,
aes(x = long, y = lat, map_id = region),
fill="#ffffff", color="#ffffff", size=0.15)
gg
gg <- gg + geom_map(data=df, map = us_states,
aes(fill=Total_Enroll, map_id=Region),
color="#ffffff", size=0.15)
gg
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(dplyr)
library(caret)
df <- read.csv("UniversalBank.csv", stringsAsFactors = TRUE)
str(df)
library(fastDummies)
df <- df %>% mutate(dummy_cols(Education))
df$Education <- factor(df$Education, levels = c(1, 2, 3),
labels = c("Undergrad", "Graduate", "Advanced/Professional"))
df$Personal_Loan <- factor(df$Personal_Loan)
df <- select(df, -c(Id, ZIP_Code, Education, ".data"))
df <- df %>% rename(
"Undergrad" = ".data_1",
"Graduate" = ".data_2",
"Advanced/Professional" = ".data_3"
)
glimpse(df)
View(df)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(dplyr)
library(caret)
df <- read.csv("UniversalBank.csv", stringsAsFactors = TRUE)
str(df)
library(fastDummies)
df <- df %>% mutate(dummy_cols(Education))
df$Education <- factor(df$Education, levels = c(1, 2, 3),
labels = c("Undergrad", "Graduate", "Advanced/Professional"))
df$Personal_Loan <- factor(df$Personal_Loan)
df <- select(df, -c(Id, ZIP_Code, Education, ".data"))
df <- df %>% rename(
"Undergrad" = ".data_1",
"Graduate" = ".data_2",
"Advanced/Professional" = ".data_3"
)
glimpse(df)
fitControl <- trainControl(method = "cv", number = 5)
set.seed(100)
logit_fit <- train(factor(Personal_Loan) ~ ., data = df,trControl = fitControl, family = binomial(link = "logit"))
print(logit_fit)
confusionMatrix(logit_fit)
k.folds <- function(k) {
folds <- createFolds(df$Personal_Loan, k = k, list = TRUE, returnTrain = TRUE)
accuracies <- c()
for (i in 1:k) {
model <- glm(Personal_Loan ~ ., data = df[folds[[i]],], family = binomial(link = 'logit'))
pred_prob_cv <- predict(object = model, newdata = df[-folds[[i]],], type = "response")
pred_class_cv <- ifelse(pred_prob_cv > 0.5, 1, 0)
accuracies <- c(accuracies,
confusionMatrix(factor(pred_class_cv),
df[-folds[[i]], ]$Personal_Loan, positive = "1")$byClass['Balanced Accuracy'])
}
accuracies
}
set.seed(100)
accuracies_cv <- k.folds(5)
accuracies_cv
# Calculate the average balanced accuracy
cat('Balanced Accuracy:\n Mean = ', mean(accuracies_cv),"; ",
'Standard Deviation = ',sd(accuracies_cv), ";\n",
'95% Confidence Interval = [',
mean(accuracies_cv) - sd(accuracies_cv) * 1.96, ", ",
mean(accuracies_cv) + sd(accuracies_cv) * 1.96,"]")
## Train a logistic regression model with repeated 5-fold cross-validation
fitControl_rcv <- trainControl(method = "repeatedcv",
number = 5,
repeats = 200,
classProbs = TRUE,
summaryFunction = twoClassSummary)
set.seed(100)
logit_fit_rcv <- train(factor(ifelse(Personal_Loan==1, 'Yes', 'No'), levels = c('Yes','No')) ~ .,
data = df,
trControl = fitControl_rcv,
method="glm", family=binomial(link='logit'),
metric = "ROC")
## Train a logistic regression model with repeated 5-fold cross-validation
fitControl_rcv <- trainControl(method = "repeatedcv",
number = 5,
repeats = 200,
classProbs = TRUE,
summaryFunction = twoClassSummary)
set.seed(100)
logit_fit_rcv <- train(factor(ifelse(Personal_Loan==1, 'Yes', 'No'), levels = c('Yes','No')) ~ .,
data = df,
trControl = fitControl_rcv,
method="glm", family=binomial(link='logit'),
metric = "ROC")
print(logit_fit_rcv)
print(logit_fit_rcv)
confusionMatrix(logit_fit_rcv)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(dplyr)
library(caret)
df <- read.csv("UniversalBank.csv", stringsAsFactors = TRUE)
str(df)
library(fastDummies)
df <- df %>% mutate(dummy_cols(Education))
df$Education <- factor(df$Education, levels = c(1, 2, 3),
labels = c("Undergrad", "Graduate", "Advanced/Professional"))
df$Personal_Loan <- factor(df$Personal_Loan)
df <- select(df, -c(Id, ZIP_Code, Education, ".data"))
df <- df %>% rename(
"Undergrad" = ".data_1",
"Graduate" = ".data_2",
"Advanced/Professional" = ".data_3"
)
glimpse(df)
fitControl <- trainControl(method = "cv", number = 5)
set.seed(100)
logit_fit <- train(factor(Personal_Loan) ~ ., data = df,trControl = fitControl, family = binomial(link = "logit"))
print(logit_fit)
confusionMatrix(logit_fit)
k.folds <- function(k) {
folds <- createFolds(df$Personal_Loan, k = k, list = TRUE, returnTrain = TRUE)
accuracies <- c()
for (i in 1:k) {
model <- glm(Personal_Loan ~ ., data = df[folds[[i]],], family = binomial(link = 'logit'))
pred_prob_cv <- predict(object = model, newdata = df[-folds[[i]],], type = "response")
pred_class_cv <- ifelse(pred_prob_cv > 0.5, 1, 0)
accuracies <- c(accuracies,
confusionMatrix(factor(pred_class_cv),
df[-folds[[i]], ]$Personal_Loan, positive = "1")$byClass['Balanced Accuracy'])
}
accuracies
}
set.seed(100)
accuracies_cv <- k.folds(5)
accuracies_cv
# Calculate the average balanced accuracy
cat('Balanced Accuracy:\n Mean = ', mean(accuracies_cv),"; ",
'Standard Deviation = ',sd(accuracies_cv), ";\n",
'95% Confidence Interval = [',
mean(accuracies_cv) - sd(accuracies_cv) * 1.96, ", ",
mean(accuracies_cv) + sd(accuracies_cv) * 1.96,"]")
## Train a logistic regression model with repeated 5-fold cross-validation
fitControl_rcv <- trainControl(method = "repeatedcv",
number = 5,
repeats = 200,
classProbs = TRUE,
summaryFunction = twoClassSummary)
set.seed(100)
logit_fit_rcv <- train(factor(ifelse(Personal_Loan==1, 'Yes', 'No'), levels = c('Yes','No')) ~ .,
data = df,
trControl = fitControl_rcv,
method="glm", family=binomial(link='logit'),
metric = "ROC")
print(logit_fit_rcv)
confusionMatrix(logit_fit_rcv)
set.seed(100)
LDA_fit_rcv <- train(factor(ifelse(Personal_Loan==1, 'Yes', 'No'), levels = c('Yes','No')) ~ .,
data = df,
trControl = fitControl_rcv,
method="lda", family=binomial(link='logit'),
metric = "ROC")
print(LDA_fit_rcv)
confusionMatrix(LDA_fit_rcv)
confusionMatrix(factor(predict(LDA_fit_rcv, newdata = df), levels = c("No", "Yes"),
labels = c("0", "1")),
df$Personal_Loan, positive = '1')
set.seed(100)
QDA_fit <- train(factor(ifelse(Personal_Loan==1, 'Yes', 'No'), levels = c('Yes','No')) ~ .,
data = df,
trControl = fitControl_rcv,
method="qda", family=binomial(link='logit'),
metric = "ROC")
cat("95% CI of QDA (normal approximation) = ",
"(",
mean(bootstrap_acc_qda, 0.025)-1.96*sd(bootstrap_acc_qda),
", ",
mean(bootstrap_acc_qda, 0.025)+1.96*sd(bootstrap_acc_qda),
")")
# Set the number of bootstraps
n_bootstraps <- 1000
# Initiate vectors of performance metric
bootstrap_acc_logit <- NULL
bootstrap_acc_lda <- NULL
bootstrap_acc_qda <- NULL
# Set the random number seed
set.seed(100)
for (i in 1:n_bootstraps){
# Get a bootstrap of test dataset
resample_test <- df[sample(nrow(df), replace = TRUE),]
# Calculate predicted outcome
logit_resample_pred <- predict(logit_fit_rcv, newdata = resample_test)
#logit_resample_pred <- ifelse(logit_resample_prob > 0.5, 1, 0)
lda_resample_pred <- predict(LDA_fit_rcv, newdata = resample_test)
qda_resample_pred <- predict(QDA_fit, newdata = resample_test)
# Calculate accuracy of the logit model using the bootstrap
bootstrap_acc_logit <- c(bootstrap_acc_logit, mean(logit_resample_pred == factor(ifelse(resample_test$Personal_Loan==1, 'Yes', 'No'), levels = c('Yes','No'))))
# Calculate f1 score of the logit model using the bootstrap
bootstrap_acc_lda <- c(bootstrap_acc_lda, mean(lda_resample_pred == factor(ifelse(resample_test$Personal_Loan==1, 'Yes', 'No'), levels = c('Yes','No'))))
bootstrap_acc_qda <- c(bootstrap_acc_qda, mean(qda_resample_pred == factor(ifelse(resample_test$Personal_Loan==1, 'Yes', 'No'), levels = c('Yes','No'))))
}
confusionMatrix(factor(predict(LDA_fit_rcv, newdata = df), levels = c("No", "Yes"),
labels = c("0", "1")),
df$Personal_Loan, positive = '1')
set.seed(100)
QDA_fit <- train(factor(ifelse(Personal_Loan==1, 'Yes', 'No'), levels = c('Yes','No')) ~ .,
data = df,
trControl = fitControl_rcv,
method="qda", family=binomial(link='logit'),
metric = "ROC")
